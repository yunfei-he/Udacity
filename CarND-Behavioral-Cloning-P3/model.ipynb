{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Flatten, Lambda \n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Cropping2D, Dropout\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model_path = 'model.h5'\n",
    "\n",
    "is_first_train = True\n",
    "train_data_path = '/opt/bc_data/'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    is_first_train = False\n",
    "    train_data_path = '/opt/yunfei/'\n",
    "    \n",
    "csv_log_file = train_data_path + 'driving_log.csv'\n",
    "image_data_path = train_data_path + 'IMG/'\n",
    "\n",
    "\n",
    "samples = []\n",
    "with open(csv_log_file) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # skip first row\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "\n",
    "# samples = samples[:100]\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "def augment_images(images, angles):\n",
    "    output_images = []\n",
    "    output_angles = []\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        angle = angles[i]\n",
    "        output_images.append(image)\n",
    "        output_angles.append(angle)\n",
    "        output_images.append(cv2.flip(image,1))\n",
    "        output_angles.append(angle*-1.0)\n",
    "        \n",
    "    return output_images, output_angles\n",
    "        \n",
    "def generate_batch(batch_samples):\n",
    "    images = []\n",
    "    angles = []\n",
    "    for batch_sample in batch_samples:\n",
    "        name = image_data_path+batch_sample[0].split('/')[-1]\n",
    "        center_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)\n",
    "        center_angle = float(batch_sample[3])\n",
    "        # center\n",
    "        images.append(center_image)\n",
    "        angles.append(center_angle)\n",
    "        \n",
    "        correction = 0.2\n",
    "        # left image\n",
    "        left = image_data_path+batch_sample[1].split('/')[-1]\n",
    "        images.append(cv2.cvtColor(cv2.imread(left), cv2.COLOR_BGR2RGB))\n",
    "        angles.append(center_angle + correction)\n",
    "        # right image\n",
    "        right = image_data_path+batch_sample[2].split('/')[-1]\n",
    "        images.append(cv2.cvtColor(cv2.imread(right), cv2.COLOR_BGR2RGB))\n",
    "        angles.append(center_angle - correction)\n",
    "        \n",
    "    images, angles = augment_images(images, angles)\n",
    "    return images, angles\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images, angles = generate_batch(batch_samples)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            # print(X_train.shape)\n",
    "            # print(y_train.shape)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# ch, row, col = 3, 90, 320  # Trimmed image format\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.0, input_shape=(160,320,3)))\n",
    "    # Crop the image\n",
    "    model.add(Cropping2D(cropping=((60,20), (0,0))))\n",
    "\n",
    "    # model.add(... finish defining the rest of your model architecture here ...)\n",
    "    model.add(Conv2D(24, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2, 2)))\n",
    "    model.add(Conv2D(36, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2, 2)))\n",
    "    model.add(Conv2D(48, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "  \n",
    "\n",
    "    #model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def load_previous_model():\n",
    "    model = load_model(model_path)\n",
    "    return model\n",
    "\n",
    "def first_train():\n",
    "    model = baseline_model()\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    early_stopping_monitor = EarlyStopping(patience=5)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    history_object = model.fit_generator(train_generator, samples_per_epoch= \n",
    "                len(train_samples), validation_data=validation_generator, \n",
    "                nb_val_samples=len(validation_samples), nb_epoch=100, verbose=1, callbacks=[early_stopping_monitor, checkpoint])\n",
    "\n",
    "    # model.save('model.h5')\n",
    "    return history_object\n",
    "\n",
    "def continue_train():\n",
    "    model = load_previous_model()\n",
    "    early_stopping_monitor = EarlyStopping(patience=2)\n",
    "    history_object = model.fit_generator(train_generator, samples_per_epoch= \n",
    "                len(train_samples), validation_data=validation_generator, \n",
    "                nb_val_samples=len(validation_samples), nb_epoch=100, verbose=1, callbacks=[early_stopping_monitor])\n",
    "\n",
    "    model.save('model.h5')\n",
    "    return history_object\n",
    "\n",
    "history_object = []\n",
    "if (is_first_train == True):\n",
    "    history_object = first_train()\n",
    "else:\n",
    "    history_object = continue_train()\n",
    "### print the keys contained in the history object\n",
    "#print(history_object.history.keys())\n",
    "#print(history_object.history['loss'])\n",
    "#print(history_object.history['val_loss'])\n",
    "### plot the training and validation loss for each epoch\n",
    "# plt.plot(history_object.history['loss'])\n",
    "# plt.plot(history_object.history['val_loss'])\n",
    "# plt.title('model mean squared error loss')\n",
    "# plt.ylabel('mean squared error loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
